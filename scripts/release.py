#!/usr/bin/env uv run --with tomli

from __future__ import annotations

import functools
import json
import os
import shutil
import subprocess
import sys
import tarfile
import textwrap
import webbrowser
import zipfile
from pathlib import Path
from tempfile import TemporaryDirectory

try:  # Python 3.11+
    import tomllib  # type: ignore[attr-defined]
except ModuleNotFoundError:  # pragma: no cover - fallback for older Python
    import tomli as tomllib  # type: ignore[no-redef]


ROOT = Path(__file__).resolve().parents[1]
DIST_DIR = ROOT / "target" / "dist"
OPENSSL_VENDOR_ROOT = ROOT / "target" / "vendored-openssl"
OPENSSL_BUILD_CACHE = ROOT / "target" / "openssl-build"


def extend_path() -> None:
    extras = [
        Path.home() / ".cargo" / "bin",
        Path.home() / ".local" / "bin",
        Path.home() / ".local" / "bin" / "bin",
    ]
    current = os.environ.get("PATH", "")
    paths = current.split(os.pathsep) if current else []
    updated = paths[:]
    for extra in extras:
        extra_str = str(extra)
        if extra.exists() and extra_str not in paths:
            updated.append(extra_str)
    if updated != paths:
        os.environ["PATH"] = os.pathsep.join(updated)


def read_manifest() -> dict:
    manifest_path = ROOT / "Cargo.toml"
    try:
        return tomllib.loads(manifest_path.read_text())
    except FileNotFoundError as exc:
        sys.exit(f"Unable to read Cargo.toml: {exc}")


def collect_targets(manifest: dict) -> list[str]:
    metadata = manifest.get("workspace", {}).get("metadata", {})
    targets = metadata.get("dist", {}).get("targets")
    if not targets:
        sys.exit(
            "No release targets found in workspace.metadata.dist.targets; "
            "add them to Cargo.toml or edit scripts/release.py."
        )
    return targets


def collect_binaries(manifest: dict) -> list[str]:
    bins = [entry["name"] for entry in manifest.get("bin", []) if "name" in entry]
    if bins:
        return bins

    package_name = manifest["package"]["name"]
    metadata_raw = subprocess.run(
        ["cargo", "metadata", "--format-version", "1", "--no-deps"],
        check=True,
        capture_output=True,
        text=True,
    ).stdout
    metadata = json.loads(metadata_raw)
    for package in metadata.get("packages", []):
        if package.get("name") != package_name:
            continue
        detected = [
            target["name"]
            for target in package.get("targets", [])
            if "bin" in target.get("kind", [])
        ]
        if detected:
            return detected

    sys.exit(f"No binary targets found for package '{package_name}'.")


def ensure_tools_available() -> None:
    for cmd in ("cargo", "rustup", "gh", "git"):
        if shutil.which(cmd) is None:
            sys.exit(
                f"Required command '{cmd}' is not available in PATH. "
                "Install the missing tool and re-run the script."
            )


def ensure_windows_cross_tooling(targets: list[str], host: str) -> None:
    needs_windows = any(target.endswith("pc-windows-msvc") for target in targets)
    if not needs_windows or "windows-msvc" in host:
        return

    if shutil.which("cargo-xwin"):
        return

    print("Installing cargo-xwin to enable Windows cross-compilation.")
    run(["cargo", "install", "cargo-xwin", "--locked"])
    if shutil.which("cargo-xwin") is None:
        sys.exit(
            "cargo-xwin installation did not make the tool available in PATH. "
            "Ensure ~/.cargo/bin is on PATH and retry."
        )


def run(cmd: list[str], **kwargs) -> subprocess.CompletedProcess:
    print(f"â†’ {' '.join(cmd)}")
    return subprocess.run(cmd, check=True, **kwargs)


def current_commit() -> str:
    return (
        subprocess.run(
            ["git", "rev-parse", "HEAD"],
            check=True,
            capture_output=True,
            text=True,
        )
        .stdout.strip()
    )


def get_release(tag: str) -> dict | None:
    result = subprocess.run(
        ["gh", "release", "view", tag, "--json", "isDraft,url"],
        capture_output=True,
        text=True,
    )
    if result.returncode != 0:
        return None
    return json.loads(result.stdout)


def create_draft_release(tag: str, title: str, commit: str) -> None:
    notes = textwrap.dedent(
        """\
        Draft release generated by scripts/release.py.

        Populate the release notes before publishing.
        """
    )
    run(
        [
            "gh",
            "release",
            "create",
            tag,
            "--draft",
            "--title",
            title,
            "--notes",
            notes,
            "--target",
            commit,
        ]
    )


def ensure_draft_release(tag: str, title: str, commit: str) -> None:
    release = get_release(tag)
    if release:
        if not release.get("isDraft", False):
            sys.exit(
                f"Release {tag} already exists and is published. "
                "Delete it or bump the version before retrying."
            )
        print(f"Using existing draft release {tag}")
        return
    create_draft_release(tag, title, commit)


def ensure_rust_targets(targets: list[str]) -> None:
    for target in targets:
        run(["rustup", "target", "add", target])


def detect_host_triple() -> str:
    rustc_info = subprocess.run(
        ["rustc", "-vV"], check=True, capture_output=True, text=True
    ).stdout
    for line in rustc_info.splitlines():
        if line.startswith("host:"):
            return line.split(":", 1)[1].strip()
    sys.exit("Unable to detect rustc host triple.")


def determine_build_command(target: str, host: str) -> list[str]:
    if target.endswith("apple-darwin") and "apple-darwin" not in host:
        raise RuntimeError(
            f"Target {target} requires running the script on macOS. "
            "Re-run on a macOS host."
        )

    if target.endswith("pc-windows-msvc"):
        if target == host:
            return ["cargo", "build", "--release", "--target", target]
        if shutil.which("cargo-xwin"):
            return [
                "cargo",
                "xwin",
                "build",
                "--release",
                "--target",
                target,
            ]
        raise RuntimeError(
            f"Target {target} needs MSVC tooling. "
            "Install `cargo-xwin` for cross-compilation or run the release script on a Windows machine with the Visual Studio Build Tools installed."
        )

    if target == host:
        return ["cargo", "build", "--release", "--target", target]

    if target.endswith("unknown-linux-gnu") and "linux-gnu" not in host:
        if shutil.which("cargo-zigbuild"):
            return ["cargo", "zigbuild", "--release", "--target", target]
        if shutil.which("cross"):
            return ["cross", "build", "--release", "--target", target]
        raise RuntimeError(
            f"Target {target} needs additional cross-compilation tooling. "
            "Install `cargo-zigbuild` (recommended) or `cross`, or run the script on a Linux host."
        )

    return ["cargo", "build", "--release", "--target", target]


def is_linux_target(target: str) -> bool:
    return target.endswith("unknown-linux-gnu")


@functools.lru_cache()
def detect_openssl_sys_version() -> str:
    lock_path = ROOT / "Cargo.lock"
    if not lock_path.exists():
        sys.exit(
            "Cargo.lock is required to determine the openssl-sys version for vendoring."
        )

    try:
        lock_data = tomllib.loads(lock_path.read_text())
    except tomllib.TOMLDecodeError as exc:
        sys.exit(f"Unable to parse Cargo.lock while preparing OpenSSL: {exc}")

    for package in lock_data.get("package", []):
        if package.get("name") == "openssl-sys":
            version = package.get("version")
            if version:
                return version

    sys.exit(
        "Unable to determine the openssl-sys version from Cargo.lock; "
        "ensure openssl-sys is listed and try again."
    )


OPENSSL_ENV_CACHE: dict[str, dict[str, str]] = {}


def vendored_openssl_env(target: str, build_cmd: list[str]) -> dict[str, str]:
    if not is_linux_target(target):
        return {}

    if target in OPENSSL_ENV_CACHE:
        return OPENSSL_ENV_CACHE[target]

    vendor_dir = OPENSSL_VENDOR_ROOT / target
    openssl_version = detect_openssl_sys_version()
    metadata_path = vendor_dir / "metadata.json"

    if vendor_dir.exists():
        try:
            metadata = json.loads(metadata_path.read_text())
        except FileNotFoundError:
            metadata = {}
        except json.JSONDecodeError as exc:
            print(f"Warning: ignoring corrupt OpenSSL metadata for {target}: {exc}")
            metadata = {}

        if metadata.get("openssl-sys-version") != openssl_version:
            print(
                f"Regenerating vendored OpenSSL for {target} "
                f"(expected openssl-sys {openssl_version}, found {metadata.get('openssl-sys-version')})."
            )
            shutil.rmtree(vendor_dir, ignore_errors=True)
        else:
            env = build_env_from_vendor(vendor_dir)
            OPENSSL_ENV_CACHE[target] = env
            return env

    if not vendor_dir.exists():
        build_vendored_openssl(target, build_cmd, vendor_dir, openssl_version)

    env = build_env_from_vendor(vendor_dir)
    OPENSSL_ENV_CACHE[target] = env
    return env


def build_env_from_vendor(vendor_dir: Path) -> dict[str, str]:
    lib_dir = vendor_dir / "lib"
    include_dir = vendor_dir / "include"

    if not lib_dir.exists() or not include_dir.exists():
        sys.exit(
            f"Vendored OpenSSL appears incomplete at {vendor_dir}; "
            "remove it and re-run the release script."
        )

    env: dict[str, str] = {
        "OPENSSL_STATIC": "1",
        "OPENSSL_LIB_DIR": str(lib_dir),
        "OPENSSL_INCLUDE_DIR": str(include_dir),
        "OPENSSL_DIR": str(vendor_dir),
        "OPENSSL_NO_VENDOR": "1",
        "PKG_CONFIG_ALLOW_CROSS": "1",
    }

    pkgconfig_dir = lib_dir / "pkgconfig"
    if pkgconfig_dir.exists():
        existing = os.environ.get("PKG_CONFIG_PATH")
        env["PKG_CONFIG_PATH"] = (
            f"{pkgconfig_dir}{os.pathsep}{existing}"
            if existing
            else str(pkgconfig_dir)
        )

    return env


def build_vendored_openssl(
    target: str, build_cmd: list[str], vendor_dir: Path, openssl_version: str
) -> None:
    print(f"Preparing vendored OpenSSL ({openssl_version}) for {target}")
    OPENSSL_VENDOR_ROOT.mkdir(parents=True, exist_ok=True)
    OPENSSL_BUILD_CACHE.mkdir(parents=True, exist_ok=True)

    helper_toml = textwrap.dedent(
        f"""\
        [package]
        name = "openssl-vendor-helper"
        version = "0.1.0"
        edition = "2021"
        publish = false

        [lib]
        path = "lib.rs"

        [dependencies]
        openssl-sys = {{ version = "{openssl_version}", features = ["vendored"] }}
        """
    )

    # Use a system temp dir so Cargo doesn't treat this helper crate as part of the workspace.
    with TemporaryDirectory() as tmp_dir_str:
        tmp_dir = Path(tmp_dir_str)
        (tmp_dir / "lib.rs").write_text("pub fn _vendored_openssl_marker() {}\n")
        (tmp_dir / "Cargo.toml").write_text(helper_toml)

        helper_env = os.environ.copy()
        helper_env.update(
            {
                "OPENSSL_STATIC": "1",
                "PKG_CONFIG_ALLOW_CROSS": "1",
                "CARGO_TARGET_DIR": str(OPENSSL_BUILD_CACHE),
            }
        )

        run(build_cmd, cwd=tmp_dir, env=helper_env)

    build_root = OPENSSL_BUILD_CACHE / target / "release" / "build"
    install_dirs = sorted(
        build_root.glob("openssl-sys-*/out/openssl-build/install"),
        key=lambda path: path.stat().st_mtime,
        reverse=True,
    )

    if not install_dirs:
        sys.exit(
            "Unable to locate the vendored OpenSSL build artifacts. "
            "Check the build output above for details."
        )

    install_dir = install_dirs[0]
    temp_target = vendor_dir.with_name(f".{vendor_dir.name}.tmp")
    if temp_target.exists():
        shutil.rmtree(temp_target)
    shutil.copytree(install_dir, temp_target)

    metadata = {
        "openssl-sys-version": openssl_version,
        "generated-by": "scripts/release.py",
        "target": target,
    }
    (temp_target / "metadata.json").write_text(json.dumps(metadata, indent=2))

    if vendor_dir.exists():
        shutil.rmtree(vendor_dir)
    temp_target.rename(vendor_dir)

def order_targets(targets: list[str], host: str) -> list[str]:
    def priority(target: str) -> tuple[int, str]:
        if target == host:
            return (0, target)
        if "apple-darwin" in host and target.endswith("apple-darwin"):
            return (1, target)
        if target.endswith("unknown-linux-gnu"):
            return (2, target)
        return (3, target)

    return sorted(targets, key=priority)


def build_release_binaries(targets: list[str], host: str) -> tuple[list[str], list[tuple[str, str]]]:
    built: list[str] = []
    skipped: list[tuple[str, str]] = []
    base_env = os.environ.copy()
    for target in order_targets(targets, host):
        try:
            cmd = determine_build_command(target, host)
        except RuntimeError as exc:
            skipped.append((target, str(exc)))
            continue
        env = base_env.copy()
        env.update(vendored_openssl_env(target, cmd))
        run(cmd, env=env)
        built.append(target)
    return built, skipped


def files_to_package(bin_names: list[str], target: str) -> list[Path]:
    release_dir = ROOT / "target" / target / "release"
    suffix = ".exe" if "windows" in target else ""
    binaries = []
    for bin_name in bin_names:
        candidate = release_dir / f"{bin_name}{suffix}"
        if not candidate.exists():
            sys.exit(f"Expected build artifact missing: {candidate}")
        binaries.append(candidate)

    extras = []
    for extra in ("README.md", "LICENSE", "LICENSE-MIT", "LICENSE-APACHE"):
        extra_path = ROOT / extra
        if extra_path.exists():
            extras.append(extra_path)

    return binaries + extras


def package_artifacts(
    artifact_prefix: str, version: str, bin_names: list[str], targets: list[str]
) -> list[Path]:
    DIST_DIR.mkdir(parents=True, exist_ok=True)
    artifacts: list[Path] = []
    for target in targets:
        archive_base = f"{artifact_prefix}-{version}-{target}"
        archive_path: Path
        files = files_to_package(bin_names, target)

        with TemporaryDirectory() as tmp_dir_str:
            tmp_dir = Path(tmp_dir_str)
            for file_path in files:
                shutil.copy2(file_path, tmp_dir / file_path.name)

            if "windows" in target:
                archive_path = DIST_DIR / f"{archive_base}.zip"
                with zipfile.ZipFile(
                    archive_path, mode="w", compression=zipfile.ZIP_DEFLATED
                ) as zipf:
                    for file_path in tmp_dir.iterdir():
                        zipf.write(file_path, arcname=file_path.name)
            else:
                archive_path = DIST_DIR / f"{archive_base}.tar.gz"
                with tarfile.open(archive_path, mode="w:gz") as tarf:
                    for file_path in tmp_dir.iterdir():
                        tarf.add(file_path, arcname=file_path.name)

        artifacts.append(archive_path)
        print(f"Packaged {archive_path}")

    return artifacts


def upload_artifacts(tag: str, artifacts: list[Path]) -> None:
    for artifact in artifacts:
        run(["gh", "release", "upload", tag, str(artifact), "--clobber"])


def open_release_in_browser(tag: str) -> None:
    result = subprocess.run(
        ["gh", "release", "view", tag, "--json", "url", "--jq", ".url"],
        check=True,
        capture_output=True,
        text=True,
    )
    url = result.stdout.strip()
    if not url:
        print("Release URL not found; open the draft manually.")
        return
    print(f"Opening {url}")
    if not webbrowser.open(url):
        print("Unable to launch browser automatically; open the URL above.")


def main() -> None:
    os.chdir(ROOT)
    extend_path()
    ensure_tools_available()

    manifest = read_manifest()
    package = manifest["package"]
    package_name = package["name"]
    package_metadata = package.get("metadata") or {}
    dist_metadata = package_metadata.get("dist") if isinstance(package_metadata, dict) else {}
    if not isinstance(dist_metadata, dict):
        dist_metadata = {}
    release_name = dist_metadata.get("release_name", package_name)
    artifact_prefix = dist_metadata.get("artifact_prefix", release_name)
    version = package["version"]
    tag = f"v{version}"

    targets = collect_targets(manifest)
    bin_names = collect_binaries(manifest)

    commit = current_commit()
    ensure_draft_release(tag, f"{release_name} {version}", commit)
    ensure_rust_targets(targets)
    host = detect_host_triple()
    ensure_windows_cross_tooling(targets, host)
    built_targets, skipped_targets = build_release_binaries(targets, host)
    if not built_targets:
        sys.exit("No targets were built. Resolve the issues above and retry.")

    artifacts = package_artifacts(artifact_prefix, version, bin_names, built_targets)
    upload_artifacts(tag, artifacts)
    open_release_in_browser(tag)

    if skipped_targets:
        print("The following targets were skipped:")
        for target, reason in skipped_targets:
            print(f"  - {target}: {reason}")


if __name__ == "__main__":
    try:
        main()
    except subprocess.CalledProcessError as exc:
        sys.exit(exc.returncode)
